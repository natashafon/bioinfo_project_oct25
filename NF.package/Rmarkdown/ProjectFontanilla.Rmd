---
title: "Project October 2025"
author: "Natasha Fontanilla"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Project October 2025}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}


# TASK 1

## DATA.TABLE VERSION

```{r, echo=TRUE}
# DATA.TABLE VERSION 
#' @param counts_file path to CSV with columns containing gene, sample_id, count
#' @param meta_file path to CSV with columns containing sample_id,condition,
#' batch,patient_id and timepoint
#' @return list(merged_df, filtered_df, gene_summary_df, per_condition_mean_df) 

task1_dt <- function(counts_file = "bulk_counts_long.csv",
                     meta_file   = "sample_metadata.csv") {
# Load libraries
  library(data.table)

# Read th CSV files
counts <- fread(counts_file)   # columns: gene, sample_id, count
meta   <- fread(meta_file)    # columns: sample_id, condition, ...

# Ensure sample_id is character
counts[, sample_id := as.character(sample_id)]
meta[,   sample_id := as.character(sample_id)]

# Join on sample_id
merged <- merge(counts, meta, by = "sample_id", sort = FALSE)

# Keep only treated samples and genes starting with "GENE_00"
filtered <- merged[
  condition == "treated" & grepl("^GENE_00", gene)
]


# Mean and median count by gene 
gene_summary <- filtered[, .(
  mean_count   = mean(count, na.rm = TRUE),
  median_count = median(count, na.rm = TRUE)
), by = gene][order(gene)]


# Per-condition mean counts by gene 
per_condition_mean <- merged[, .(
  mean_count = mean(count, na.rm = TRUE)
), by = .(gene, condition)][order(gene, condition)]


return(list(
  merged = merged,
  filtered = filtered,
  gene_summary = gene_summary,
  per_condition_mean = per_condition_mean
))
}

# SHOW RESULTS
res_dt <- task1_dt()
head(res_dt$filtered, 5)
head(res_dt$gene_summary, 5)
head(res_dt$per_condition_mean, 5)

```

## DATA.FRAME VERSION

```{r echo=TRUE}
# DATA.FRAME VERSION 
#' param counts_file path to CSV with columns: gene, sample_id, count
#' @param meta_file   path to CSV with columns: sample_id, condition, ...
#' @return list(merged_df, filtered_df, gene_summary_df, per_condition_mean_df)

task1_df <- function(counts_file = "bulk_counts_long.csv",
                     meta_file   = "sample_metadata.csv") {
  
# Read CSV files
counts_df <- read.csv(counts_file, stringsAsFactors = FALSE)
meta_df   <- read.csv(meta_file,  stringsAsFactors = FALSE)

# Ensure sample_id is character
counts_df$sample_id <- as.character(counts_df$sample_id)
meta_df$sample_id   <- as.character(meta_df$sample_id)

# Join on sample_id
merged_df <- merge(counts_df, meta_df, by = "sample_id", sort = FALSE)

# Filter treated + genes starting with "GENE_00"
filtered_df <- merged_df[
  merged_df$condition == "treated" & grepl("^GENE_00", merged_df$gene),
]

# Mean and median by gene (on filtered)
mean_by_gene   <- aggregate(count ~ gene, data = filtered_df, FUN = function(x) mean(x, na.rm = TRUE))
median_by_gene <- aggregate(count ~ gene, data = filtered_df, FUN = function(x) median(x, na.rm = TRUE))

# Merge summaries and align column names/order to data.table version

gene_summary_df <- merge(mean_by_gene, median_by_gene, by = "gene")

names(gene_summary_df) <- c("gene", "mean_count", "median_count")

gene_summary_df <- gene_summary_df[order(gene_summary_df$gene), ]

# Per-condition mean counts by gene (on all merged)
per_condition_mean_df <- aggregate(
  count ~ gene + condition,
  data = merged_df,
  FUN = function(x) mean(x, na.rm = TRUE)
)
per_condition_mean_df <- per_condition_mean_df[order(per_condition_mean_df$gene, per_condition_mean_df$condition), ]

return(list(
  merged_df = merged_df,
  filtered_df = filtered_df,
  gene_summary_df = gene_summary_df,
  per_condition_mean_df = per_condition_mean_df
))
}

# SHOW RESULTS
res_df <- task1_df()
head(res_df$filtered_df, 5)
head(res_df$gene_summary_df, 5)
head(res_df$per_condition_mean_df, 5)
```

# TASK 2

## DATA.TABLE VERSION

```{r echo=TRUE}
#TASK 2 : Add QC-style derived columns without copying.


# DATA.TABLE VERSION
#' @param counts_file path to CSV with columns containing gene, sample_id, count
#' @return list containing dt and df versions

task2_dt <- function(
    counts_file = "bulk_counts_long.csv") {

# Load the library
library(data.table)

# Read the CSV file
counts_dt <- fread(counts_file)

# Adding log2 counts coulumn which is applied to all rows
counts_dt[, log2_count := log2(count + 1)]

# Adding a binary flag high if count >100 
counts_dt[, high := count > 100]

# Overwrite 'high' if the count is higher thant the median value for a certain gene
counts_dt[, high := count > median(count), by = gene]

return(counts_dt)
}

# SHOW RESULTS
res_dt2 <- task2_dt("bulk_counts_long.csv")
head(res_dt2, 5)
```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION
#' @param counts_file path to CSV with columns: gene, sample_id, count
#' @return data.frame with added QC-style columns (log2_count, high)

# Read the CSV file
task2_df <- function(path = counts_file) {


#  Read CSV file
counts_df <- read.csv(path, stringsAsFactors = FALSE)

# Add a new column: log2_count
counts_df$log2_count <- log2(counts_df$count + 1)

# Add a column: high = TRUE if count > 100
counts_df$high <- counts_df$count > 100

# Compute median count per gene
med_by_gene <- tapply(counts_df$count, counts_df$gene, median)

# Overwrite 'high' using gene-wise median
counts_df$high <- counts_df$count > med_by_gene[counts_df$gene]

return(counts_df)
}

# SHOW RESULTS
res_df2 <- task2_df("bulk_counts_long.csv")
head(res_df2, 5)


```

# TASK 3

## DATA.TABLE VERSION

```{r echo=TRUE, message=FALSE, warning=FALSE}
#DATA.TABLE VERSION

#' @param counts_file path to CSV with columns: gene, sample_id, count
#' @param sample_metadata path to CSV with columns: sample_id, condition, batch, patient_id, timepoint
#' @return list containing merged data.table and benchmark results


task3_dt <- function(counts_file = "bulk_counts_long.csv",
                     sample_metadata = "sample_metadata.csv") {
  
# Load needed libraries
library(data.table)
library(microbenchmark)

# Read the files
counts_dt3 <- fread(counts_file)
meta_dt3   <- fread(sample_metadata)
  
# Set key and join by sample_id
setkey(meta_dt3, sample_id)
merged_dt3 <- counts_dt3[meta_dt3, on = "sample_id", nomatch = 0L]
  
  
# Benchmark before and after index
gene_query   <- merged_dt3$gene[1]
sample_query <- merged_dt3$sample_id[1]
  
before_time <- microbenchmark(
no_index = merged_dt3[gene == gene_query & sample_id == sample_query],
times = 20L
)

# Add secondary index
setindexv(merged_dt3, c("gene", "sample_id"))
after_time <- microbenchmark(
    with_index = merged_dt3[gene == gene_query & sample_id == sample_query],
    times = 20L
)
  
# Combine benchmark results
benchmark3 <- rbind(
    data.table(expr = "no_index",  median_ms = median(before_time$time) / 1e6),
    data.table(expr = "with_index", median_ms = median(after_time$time) / 1e6)
  )
  benchmark3[, speedup := round(benchmark3$median_ms[1] / benchmark3$median_ms, 2)]
  
return(list(
merged_dt3 = merged_dt3,
benchmark3 = benchmark3
  ))
}

# SHOW RESULTS 
res_dt3 <- task3_dt("bulk_counts_long.csv", "sample_metadata.csv")

head(res_dt3$merged_dt3, 5)

head(res_dt3$benchmark3, 5)

```

## DATA.FRAME VERSION

```{r echo=TRUE, message=TRUE, warning=TRUE}
# DATA.FRAME VERSION

#' @param counts_file path to CSV with columns: gene, sample_id, count
#' @param sample_metadata path to CSV with columns: sample_id, condition, batch, patient_id, timepoint
#' @return merged data.frame


task3_df <- function(counts_file = "bulk_counts_long.csv",
                     sample_metadata = "sample_metadata.csv") {
  
# Read data
counts_df3 <- read.csv(counts_file, stringsAsFactors = FALSE)
meta_df3   <- read.csv(sample_metadata, stringsAsFactors = FALSE)
  
  
# Merge using base R
merged_df3 <- merge(counts_df3, meta_df3, by = "sample_id", all = FALSE)

# Define query 
gene_query   <- merged_df3$gene[1]
sample_query <- merged_df3$sample_id[1]


# Benchmark
benchmark_df3 <- microbenchmark(
  subset_lookup = merged_df3[merged_df3$gene == gene_query &
                               merged_df3$sample_id == sample_query, ],
  times = 100L
)

# Subset 
subset_df3 <- merged_df3[merged_df3$gene == gene_query & merged_df3$sample_id == sample_query, ]
  
return(list(
  merged_df3 = merged_df3,
  benchmark_df3 = benchmark_df3,
  subset_df3 = subset_df3))
}


# SHOW RESULTS 

res_df3 <- task3_df("bulk_counts_long.csv", "sample_metadata.csv")

head(res_df3$merged_df3, 5)
head(res_df3$benchmark_df3)
head(res_df3$subset_df3, 5)

```

# TASK 4

## DATA.TABLE VERSION

```{r echo=TRUE}
# DATA TABLE VERSION 

#' @param counts_file path to CSV with columns: gene, sample_id, count
#' @param sample_metadata path to CSV with columns: sample_id, condition, batch, patient_id, timepoint
#' @return list containing annotated table, patient totals, and top10 per condition

task4_dt <- function(counts_file = "bulk_counts_long.csv",
                     sample_metadata = "sample_metadata.csv") {
# Load library
library(data.table)
  
# Read both files
counts_dt4 <- fread(counts_file)
meta_dt4   <- fread(sample_metadata)
  
# Annotate counts with metadata (join by sample_id)
counts_annotated <- merge(counts_dt4, meta_dt4, by = "sample_id", all.x = TRUE)
  
# Compute per-patient total counts (then sort by patient_id)
counts_patient_total <- counts_annotated[, .(total_count = sum(count)), 
                                         by = patient_id]
setorder(counts_patient_total, patient_id)   
  
# Find top 10 genes by average count within each condition
counts_top_genes <- counts_annotated[, .(avg_count = mean(count)), 
                                     by = .(condition, gene)]
  
# Order descending and pick top 10 per condition
counts_top10_by_condition <- counts_top_genes[order(condition, -avg_count), 
                                              .SD[1:10], by = condition]

  return(list(
    counts_annotated = counts_annotated,
    counts_patient_total = counts_patient_total,
    counts_top10_by_condition = counts_top10_by_condition
  ))
}

# SHOW RESULTS
res_dt4 <- task4_dt("bulk_counts_long.csv", "sample_metadata.csv")
head(res_dt4$counts_patient_total, 5)
head(res_dt4$counts_top10_by_condition, 5)
```

## DATA.FRAME VERSION

```{r echo=TRUE}
# DATA.FRAME VERSION 
#' @param counts_file path to CSV with columns: gene, sample_id, count
#' @param sample_metadata path to CSV with columns: sample_id,
#' condition, batch, patient_id, timepoint
#' @return list containing annotated data.frame, patient totals, 
#' and top10 per condition

task4_df <- function(counts_file = "bulk_counts_long.csv",
                     sample_metadata = "sample_metadata.csv") {
  
# Read data
counts_df4 <- read.csv(counts_file, stringsAsFactors = FALSE)
meta_df4   <- read.csv(sample_metadata, stringsAsFactors = FALSE)
  
# Annotate counts with metadata (prevent automatic sorting)
counts_annotated <- merge(counts_df4, meta_df4, by = "sample_id", all.x = TRUE, 
                          sort = FALSE)
  
# Compute total counts per patient
counts_patient_totals <- aggregate(count ~ patient_id, data = counts_annotated,
                                   FUN = sum)
colnames(counts_patient_totals)[2] <- "total_count"
  
# Sort the data
counts_patient_totals <- counts_patient_totals[order(counts_patient_totals$patient_id), ]
  
# Find top 10 genes by average count within each condition
counts_avg_by_condition <- aggregate(count ~ condition + gene, 
                                     data = counts_annotated, FUN = mean)
colnames(counts_avg_by_condition)[3] <- "avg_count"
  
# Order and extract top 10 per condition
counts_top10_genes <- do.call(rbind, lapply(split(counts_avg_by_condition, counts_avg_by_condition$condition), function(x) {
    x <- x[order(-x$avg_count), ]
    head(x, 10)
  }))
  
rownames(counts_top10_genes) <- NULL   # remove control.* rownames
  
  return(list(
    counts_annotated = counts_annotated,
    counts_patient_totals = counts_patient_totals,
    counts_top10_genes = counts_top10_genes
  ))
}

# SHOW RESULTS
res_df4 <- task4_df("bulk_counts_long.csv", "sample_metadata.csv")
head(res_df4$counts_patient_totals, 5)
head(res_df4$counts_top10_genes, 5)
```

# TASK 5

## DATA.TABLE VERSION

```{r}
# DATA.TABLE VERSION

#' @param labs_file path to CSV with columns: patient_id, time_iso, lab, value
#' @param ref_file  path to CSV with columns: lab, lower, upper
#' @param meta_file optional metadata file (not used here)
#' @export 

task5_dt <- function(labs_file = "clinical_labs.csv",
                     ref_file  = "lab_reference_ranges.csv",
                     meta_file = "sample_metadata.csv") {
  
#Load library
  library(data.table)
  
# Read data
  labs_dt <- fread(labs_file)
  ref_dt  <- fread(ref_file)
  
# Remove duplicate M/F reference ranges
  ref_dt <- unique(ref_dt[, .(lab, lower, upper)])
  
# Merge by lab and classify using vectorised conditions
  merged <- merge(labs_dt, ref_dt, by = "lab", all.x = TRUE)
  
  merged[, status := fifelse(value >= lower & value <= upper,
                             "normal", "out_of_range")]
#Summaries
  abnormal_by_patient_dt5 <- merged[, .(
    total_labs = .N,
    abnormal_n = sum(status == "out_of_range"),
    abnormal_rate = mean(status == "out_of_range")
  ), by = patient_id]
  
  abnormal_by_lab_dt5 <- merged[, .(
    total_patients = .N,
    abnormal_n = sum(status == "out_of_range"),
    abnormal_rate = mean(status == "out_of_range")
  ), by = lab]
  
# Order
setorder(merged, patient_id, time_iso, lab)
setorder(abnormal_by_patient_dt5, -abnormal_rate)
setorder(abnormal_by_lab_dt5, -abnormal_rate)
  
return(list(
    classified_dt5 = merged[, .(patient_id, time_iso, lab, value, status)],
    abnormal_by_patient_dt5 = abnormal_by_patient_dt5,
    abnormal_by_lab_dt5 = abnormal_by_lab_dt5
  ))
}

# SHOW RESULTS
res5 <- task5_dt()
head(res5$classified_dt5)
head(res5$abnormal_by_patient_dt5)
head(res5$abnormal_by_lab_dt5)

```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION

#' @param labs_file path to CSV with columns: patient_id, time_iso, lab, value
#' @param ref_file  path to CSV with columns: lab, lower, upper
#' @param meta_file optional metadata file (not used here)
#' @export 

task5_df <- function(labs_file = "clinical_labs.csv",
                     ref_file  = "lab_reference_ranges.csv",
                     meta_file = "sample_metadata.csv") {
  
# Read data
  labs_df <- read.csv(labs_file, stringsAsFactors = FALSE)
  ref_df  <- read.csv(ref_file,  stringsAsFactors = FALSE)
  
# Remove duplicate M/F reference ranges
  ref_df <- unique(ref_df[, c("lab", "lower", "upper")])
  
# Merge and classify vectorised
  merged <- merge(labs_df, ref_df, by = "lab", all.x = TRUE)
  merged$status <- ifelse(merged$value >= merged$lower &
                            merged$value <= merged$upper,
                          "normal", "out_of_range")
  
# Summaries 
abnormal_by_patient_df5 <- aggregate(status ~ patient_id, data = merged,
                                       FUN = function(x) mean(x == "out_of_range"))
 names(abnormal_by_patient_df5)[2] <- "abnormal_rate"
  
abnormal_by_patient_df5$total_labs <- as.numeric(table(merged$patient_id))
abnormal_by_patient_df5$abnormal_n <- round(
  abnormal_by_patient_df5$abnormal_rate * abnormal_by_patient_df5$total_labs, 0)
  
abnormal_by_lab_df5 <- aggregate(status ~ lab, data = merged,
                                   FUN = function(x) mean(x == "out_of_range"))
names(abnormal_by_lab_df5)[2] <- "abnormal_rate"
abnormal_by_lab_df5$total_patients <- as.numeric(table(merged$lab))
abnormal_by_lab_df5$abnormal_n <- round(
abnormal_by_lab_df5$abnormal_rate * abnormal_by_lab_df5$total_patients, 0)
  
# Order and return
  merged <- merged[order(merged$patient_id, merged$time_iso, merged$lab), ]
  abnormal_by_patient_df5 <- abnormal_by_patient_df5[
    order(-abnormal_by_patient_df5$abnormal_rate), ]
  abnormal_by_lab_df5 <- abnormal_by_lab_df5[
    order(-abnormal_by_lab_df5$abnormal_rate), ]
  
  return(list(
    classified_df5 = merged[, c("patient_id", "time_iso", "lab", "value", "status")],
    abnormal_by_patient_df5 = abnormal_by_patient_df5,
    abnormal_by_lab_df5 = abnormal_by_lab_df5
  ))
}

# SHOW RESULTS
res5_df <- task5_df()
head(res5_df$classified_df5)
head(res5_df$abnormal_by_patient_df5)
head(res5_df$abnormal_by_lab_df5)
```

# TASK 6

## DATA.TABLE VERSION

```{r}
# DATA.TABLE VERSION 
#' @param labs_file path to CSV with columns: patient_id, time_iso, lab, value
#' @param vitals_file path to CSV with columns: patient_id, time_iso, vital (HR/SBP), value
#' @export

task6_dt <- function(labs_file   = "clinical_labs.csv",
                     vitals_file = "vitals_time_series.csv") {
  
# Load library
library(data.table)
  
# Read files
labs   <- fread(labs_file)
vitals <- fread(vitals_file)
  
# Ensure time columns exist and convert
if (!"time_iso" %in% names(labs))   stop("Column 'time_iso' missing in labs file")
if (!"time_iso" %in% names(vitals)) stop("Column 'time_iso' missing in vitals file")
  
labs[,   lab_time   := as.POSIXct(time_iso)]
vitals[, vital_time := as.POSIXct(time_iso)]
  
# Reshape vitals to wide format (HR + SBP)
vitals_w <- dcast(vitals, patient_id + vital_time ~ vital, value.var = "value")
  
# For each lab, find nearest vital record manually
results_list <- lapply(1:nrow(labs), function(i) {
pid <- labs$patient_id[i]
t0  <- labs$lab_time[i]
subset_v <- vitals_w[vitals_w$patient_id == pid]
    
if (nrow(subset_v) == 0) {
    return(data.table(
        patient_id   = pid,
        lab          = labs$lab[i],
        value        = labs$value[i],
        lab_time     = t0,
        vital_time   = NA,
        HR           = NA_real_,
        SBP          = NA_real_,
        time_lag_min = NA_real_
      ))
    }
    
subset_v[, diff_min := abs(as.numeric(difftime(vital_time, t0, units = "mins")))]
nearest <- subset_v[which.min(diff_min)]
    nearest[, `:=`(
      patient_id   = pid,
      lab          = labs$lab[i],
      value        = labs$value[i],
      lab_time     = t0,
      time_lag_min = diff_min
    )]
    
nearest[, .(patient_id, lab, value, lab_time, vital_time, HR, SBP, time_lag_min)]
  })
  
# Combine all results
  merged_dt6 <- rbindlist(results_list, use.names = TRUE, fill = TRUE)
  
# Correlation summary (CRP only)
crp_dt <- merged_dt6[lab == "CRP"]
corr_summary_dt6 <- crp_dt[, .(
cor_CRP_HR  = cor(value, HR,  use = "complete.obs"),
cor_CRP_SBP = cor(value, SBP, use = "complete.obs")
  ), by = patient_id]
  
  return(list(
    merged_dt6 = merged_dt6,
    corr_summary_dt6 = corr_summary_dt6
  ))
}

# SHOW RESULTS
res_dt6 <- task6_dt()
head(res_dt6$merged_dt6, 5)
head(res_dt6$corr_summary_dt6, 5)

```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION 
#' @param labs_file path to CSV with columns: patient_id, time_iso, lab, value
#' @param vitals_file path to CSV with columns: patient_id, time_iso, vital, value
#' @export


task6_df <- function(labs_file   = "clinical_labs.csv",
                     vitals_file = "vitals_time_series.csv") {
  
# Read CSVs
labs   <- read.csv(labs_file, stringsAsFactors = FALSE)
vitals <- read.csv(vitals_file, stringsAsFactors = FALSE)
  
# Convert time columns
labs$lab_time     <- as.POSIXct(labs$time_iso)
vitals$vital_time <- as.POSIXct(vitals$time_iso)
  
# Reshape vitals to wide (HR + SBP)
vitals_w <- reshape(
vitals[, c("patient_id", "vital_time", "vital", "value")],
    timevar = "vital",
    idvar   = c("patient_id", "vital_time"),
    direction = "wide"
  )
  names(vitals_w) <- gsub("value.", "", names(vitals_w))
  
# For each lab, find nearest vital record
  nearest_row <- function(pid, t0) {
    d <- subset(vitals_w, patient_id == pid)
    if (nrow(d) == 0)
      return(data.frame(time_lab = NA, HR = NA, SBP = NA, time_lag_min = NA))
    diffs <- abs(as.numeric(difftime(d$vital_time, t0, units = "mins")))
    k <- which.min(diffs)
    data.frame(time_lab = d$vital_time[k],
               HR = d$HR[k],
               SBP = d$SBP[k],
               time_lag_min = diffs[k])
  }
  
merged_list <- mapply(nearest_row, labs$patient_id, labs$lab_time, SIMPLIFY = FALSE)
merged_df6  <- cbind(labs[, c("patient_id", "lab", "value", "lab_time")],
                       do.call(rbind, merged_list))
  
# Correlation summary (CRP only)
crp_df <- subset(merged_df6, lab == "CRP")
corr_summary_df6 <- do.call(rbind, lapply(split(crp_df, crp_df$patient_id), function(sub) {
    data.frame(
      patient_id  = unique(sub$patient_id),
      cor_CRP_HR  = cor(sub$value, as.numeric(sub$HR),  use = "complete.obs"),
      cor_CRP_SBP = cor(sub$value, as.numeric(sub$SBP), use = "complete.obs")
    )
  }))
  
  
return(list(
    merged_df6 = merged_df6,
    corr_summary_df6 = corr_summary_df6
  ))
}

# SHOW RESULTS
res_df6 <- task6_df()
head(res_df6$merged_df6, 5)
head(res_df6$corr_summary_df6, 5)
```

# TASK 7

## DATA.TABLE VERSION

```{r}
#  DATA.TABLE VERSION
#' @param peaks_file path to CSV file containing ATAC-seq peaks 
#'        (columns expected: chr, start, end, score, etc.)
#' @return list(chr2_window, top50_peaks)

task7_dt <- function(peaks_file = "atac_peaks.bed.csv") {
# Load library
library(data.table)
  
# Read the peaks file
peaks_dt <- fread(peaks_file)

# Subset peaks on chr2 in 2–4 Mb region
chr2_window <- peaks_dt[
  chr == "chr2" & start >= 2e6 & start <= 4e6]
  
# Order by descending score
setorder(chr2_window, -score)
  
# Select top 50 peaks (safe even if <50)
top50_peaks <- head(chr2_window, 50)

  return(list(
    chr2_window = chr2_window,
    top50_peaks = top50_peaks
  ))
}

# SHOW RESULTS
res_dt7 <- task7_dt("atac_peaks.bed.csv")
head(res_dt7$chr2_window, 5)
head(res_dt7$top50_peaks, 5)
```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION
#' @param peaks_file path to CSV file containing ATAC-seq peaks 
#'        (columns expected: chr, start, end, score, etc.)
#' @return list(chr2_window_df, top50_peaks_df)

task7_df <- function(peaks_file = "atac_peaks.bed.csv") {
# Load library
library(readr)
  
# Read the peaks file
peaks_df <- read_csv(peaks_file)
  
# Show first few lines
head(peaks_df)
  
# Subset peaks on chr2 in 2–4 Mb region
chr2_window_df <- subset(
    peaks_df,
    chr == "chr2" & start >= 2e6 & start <= 4e6
  )
  
# Order by descending score
chr2_window_df <- chr2_window_df[order(-chr2_window_df$score), ]
  
# Select top 50 peaks
top50_peaks_df <- head(chr2_window_df, 50)

return(list(
    chr2_window_df = chr2_window_df,
    top50_peaks_df = top50_peaks_df
  ))
}


# SHOW RESULTS
res_df7 <- task7_df("atac_peaks.bed.csv")
head(res_df7$chr2_window_df, 5)
head(res_df7$top50_peaks_df, 5)

```

# TASK 8

## DATA.TABLE VERSION

```{r echo=TRUE, message=FALSE, warning=FALSE}
# DATA.TABLE VERSION
#' @param counts_file path to CSV with columns containing gene, sample_id, count
#' @param meta_file path to CSV with columns containing sample_id, condition, 
#' batch, patient_id, and timepoint
#' @return data.table filtered to genes where treated mean maggiore 2× control mean

task8_dt <- function(counts_file = "bulk_counts_long.csv",
                     meta_file   = "sample_metadata.csv") {
  
# Load library 
library(data.table)
  
# Read the CSV files
counts_dt8 <- fread(counts_file)
meta_dt8   <- fread(meta_file)
  
# Merge counts with metadata by sample_id
merged_dt8 <- merge(counts_dt8, meta_dt8, by = "sample_id", sort = FALSE)
  
# Compute per-condition robust summary stats for each gene (mean, median, Q1, Q3)
statsum_dt8 <- merged_dt8[, .(
mean_count   = mean(count, na.rm = TRUE),
median_count = median(count, na.rm = TRUE),
    Q1           = quantile(count, 0.25, na.rm = TRUE),
    Q3           = quantile(count, 0.75, na.rm = TRUE)
  ), by = .(gene, condition)]
  
# View summary
print(head(statsum_dt8))
  
# Reshape to wide format (one row per gene, columns for each condition)
wide_dt8 <- dcast(statsum_dt8, gene ~ condition, value.var = "mean_count")
  
# Filter by keeping only genes where treated mean ≥ 2 × control mean
filtered_dt8 <- wide_dt8[
  !is.na(.SD$treated) &
    !is.na(.SD$control) &
    .SD$treated >= 2 * .SD$control
]

return(list(
  statsum_dt8  = statsum_dt8,
  wide_dt8     = wide_dt8,
  filtered_dt8 = filtered_dt8
  ))
}

# SHOW RESULTS 
counts_dt8_result <- task8_dt()
head(counts_dt8_result$statsum_dt8, 5)
head(counts_dt8_result$wide_dt8, 5)
head(counts_dt8_result$filtered_dt8, 5)
```

## DATA.FRAME VERSION

```{r echo=TRUE, message=FALSE, warning=FALSE}
# DATA FRAME VERSION
#' @param counts_file path to CSV with columns containing gene, sample_id, count
#' @param meta_file path to CSV with columns containing sample_id, condition,
#'  batch, patient_id, and timepoint
#' @return data frame filtered to genes where treated mean ≥ 2× control mean

task8_df <- function(counts_file = "bulk_counts_long.csv",
                     meta_file   = "sample_metadata.csv") {
  
# Load libraries
library(dplyr)
library(tidyr)
library(readr)
  
# Read CSV files
counts_df8 <- read_csv(counts_file)
meta_df8   <- read_csv(meta_file)
  
# Merge counts with metadata by sample_id
merged_df8 <- merge(counts_df8, meta_df8, by = "sample_id", sort = FALSE)
  
# Compute per-condition summary stats for each gene
statsum_df8 <- merged_df8 %>%
group_by(gene, condition) %>%
    summarise(
      mean_count   = mean(count, na.rm = TRUE),
      median_count = median(count, na.rm = TRUE),
      Q1           = quantile(count, 0.25, na.rm = TRUE),
      Q3           = quantile(count, 0.75, na.rm = TRUE),
      .groups = "drop"
    )
  
# View summary
print(head(statsum_df8))
  
# Reshape from long → wide so we can compare control vs treated
wide_df8 <- statsum_df8 %>%
  select(gene, condition, mean_count) %>%
  pivot_wider(names_from = condition, values_from = mean_count)
  
# Filter genes where treated mean ≥ 2 × control mean
filtered_df8 <- wide_df8 %>%
filter(!is.na(treated) & !is.na(control) & treated >= 2 * control)
  
return(list(
statsum_df8  = statsum_df8,
  wide_df8     = wide_df8,
   filtered_df8 = filtered_df8
  ))
}

# SHOW RESULTS 
counts_df8_result <- task8_df()
head(counts_df8_result$statsum_df8, 5)
head(counts_df8_result$wide_df8, 5)
head(counts_df8_result$filtered_df8, 5)

```

# TASK 9

## DATA.TABLE VERSION

```{r echo=TRUE, message=FALSE, warning=FALSE}
# DATA.TABLE VERSION

#' @param wide_file path to CSV with columns containing gene and 
#' sample count columns 
#' @return list(counts_long_dt, counts_mean_dt, counts_summary_dt)

task9_dt <- function(wide_file = "bulk_counts_wide.csv") {
  
# Load library
library(data.table)
  
# Read CSV file
counts_wide_dt <- fread(wide_file)   # columns: gene, S01, S02, …

str(counts_wide_dt)
  
# Identify numeric columns (sample count columns)
numeric_columns <- setdiff(names(counts_wide_dt), "gene")
numeric_columns  # should list S01, S02, …
  
# Convert from wide to long format
counts_long_dt <- melt(
  counts_wide_dt,
  id.vars = "gene",
  measure.vars = numeric_columns,
  variable.name = "sample_id",
  value.name = "count"
  )
  
setDT(counts_long_dt)

# Compute per-sample totals
counts_long_dt[, sample_total := sum(count, na.rm = TRUE), by = sample_id]

# Assign condition labels (example rule)
counts_long_dt[, condition := ifelse(
  grepl("treat", sample_id, ignore.case = TRUE),
    "treated", "control"
  )]

# Compute mean count per gene × condition
counts_mean_dt <- counts_long_dt[
    , .(mean_count = mean(count, na.rm = TRUE)),
    by = .(gene, condition)
  ][order(gene, condition)]

# Convert back to wide format (gene × condition)
counts_summary_dt <- dcast(
  counts_mean_dt,
  gene ~ condition,
  value.var = "mean_count"
  )

# Set outputs as data.table
setDT(counts_long_dt)
setDT(counts_mean_dt)
setDT(counts_summary_dt)


return(list(
  counts_long_dt    = counts_long_dt,
  counts_mean_dt    = counts_mean_dt,
  counts_summary_dt = counts_summary_dt
  ))
}


# SHOW RESULTS
counts_dt9_result <- task9_dt("bulk_counts_wide.csv")
head(counts_dt9_result$counts_long_dt, 5)
head(counts_dt9_result$counts_mean_dt, 5)
head(counts_dt9_result$counts_summary_dt, 5)
```

## DATA.FRAME VERSION

```{r echo=TRUE, message=FALSE, warning=FALSE}
#  DATA.FRAME VERSION 
#' @param wide_file path to CSV with columns containing gene and sample count columns
#' @return list(counts_long_df, counts_mean_df, counts_summary_df)

task9_df <- function(wide_file = "bulk_counts_wide.csv") {
  
# Load library
library(reshape2)
  
# Read CSV file
counts_wide_df <- read.csv(wide_file, stringsAsFactors = FALSE)
head(counts_wide_df)
str(counts_wide_df)
  
# Identify numeric columns (sample count columns)
numeric_columns <- setdiff(names(counts_wide_df), "gene")
numeric_columns  
  
# Convert from wide to long format
counts_long_df <- melt(
counts_wide_df,
id.vars = "gene",
measure.vars = numeric_columns,
variable.name = "sample_id",
value.name = "count"
  )

# Compute per-sample totals
counts_long_df$sample_total <- ave(
counts_long_df$count,
counts_long_df$sample_id,
FUN = function(x) sum(x, na.rm = TRUE)
  )


# Assign condition labels (example rule)
counts_long_df$condition <- ifelse(
  grepl("treat", counts_long_df$sample_id, ignore.case = TRUE),
  "treated", "control"
  )

  
# Compute mean count per gene × condition
counts_mean_df <- aggregate(
  count ~ gene + condition,
  data = counts_long_df,
  FUN = function(x) mean(x, na.rm = TRUE)
)

names(counts_mean_df)[3] <- "mean_count"

counts_mean_df <- counts_mean_df[order(counts_mean_df$gene, 
                                       counts_mean_df$condition), ]

# Convert back to wide format (gene × condition)
counts_summary_df <- reshape(
  counts_mean_df,
  timevar = "condition",
  idvar   = "gene",
  direction = "wide"
)

#Modify names 
names(counts_summary_df) <- gsub("^mean_count\\.", "", 
                                 names(counts_summary_df))

#Sort
col_order <- c("gene", setdiff(sort(names(counts_summary_df)), "gene"))
counts_summary_df <- counts_summary_df[, col_order]


return(list(
  counts_long_df    = counts_long_df,
  counts_mean_df    = counts_mean_df,
  counts_summary_df = counts_summary_df
  ))
}


# SHOW RESULTS
counts_df9_result <- task9_df("bulk_counts_wide.csv")
head(counts_df9_result$counts_long_df, 5)
head(counts_df9_result$counts_mean_df, 5)
head(counts_df9_result$counts_summary_df, 5)
```

# TASK 10

## DATA.TABLE VERSION

```{r}
# TASK 10 — ATAC-to-Gene Mapping

# DATA.TABLE VERSION
#'@param peaks_file Path to the CSV file of ATAC-seq peaks with columns 
#'(chr, start, end, score …)
#' @param genes_file Path to the CSV file of gene annotation with columns 
#' (chr, gene_start, gene_end, gene).

task10_dt <- function(peaks_file = "atac_peaks.bed.csv",
                      genes_file = "gene_annotation.bed.csv") {
  
library(data.table)
  
#Read data
peaks <- fread(peaks_file)
genes <- fread(genes_file)
  
#Standardize column names
setnames(peaks, 1:3, c("chr", "start", "end"))
setnames(genes, 1:4, c("chr", "gene_start", "gene_end", "gene"))
  
# Set keys
setkey(peaks, chr, start, end)
setkey(genes, chr, gene_start, gene_end)
  
#Intersect peaks with gene bodies
overlaps <- foverlaps(peaks, genes,
                        by.x = c("chr", "start", "end"),
                        type = "any", nomatch = 0L)
  
#Compute overlap length (bp)
overlaps[, overlap_bp := pmin(end, gene_end) - pmax(start, gene_start)]
overlaps <- overlaps[overlap_bp > 0]
  
#Count peaks and sum overlap per gene
peaks_per_gene <- overlaps[, .(
    n_peaks = .N,
    total_overlap_bp = sum(overlap_bp)
  ), by = gene]
  
#Top 20 genes by total overlap
top20 <- peaks_per_gene[order(-total_overlap_bp)][1:20]
  
return(list(
    overlaps_dt10 = overlaps,
    peaks_per_gene_dt10 = peaks_per_gene,
    top20_dt10 = top20
  ))
}

# SHOW RESULTS 
res_dt10 <- task10_dt("atac_peaks.bed.csv", "gene_annotation.bed.csv")
head(res_dt10$overlaps_dt10)
head(res_dt10$peaks_per_gene_dt10)
res_dt10$top20_dt10
```

## DATA.FRAME VERSION

```{r}
#DATA.FRAME VERSION 
#'@param peaks_file Path to the CSV file of ATAC-seq peaks with columns 
#'(chr, start, end, score …)
#' @param genes_file Path to the CSV file of gene annotation with columns 
#' (chr, gene_start, gene_end, gene).

task10_df <- function(peaks_file = "atac_peaks.bed.csv",
                      genes_file = "gene_annotation.bed.csv") {
  
# Read data
peaks <- read.csv(peaks_file)
genes <- read.csv(genes_file)

names(peaks)[1:3] <- c("chr", "start", "end")
names(genes)[1:4] <- c("chr", "gene_start", "gene_end", "gene")
  
#Container for overlaps
overlap_list <- list()
  
#Loop per chromosome
  for (ch in intersect(unique(peaks$chr), unique(genes$chr))) {
    p_sub <- subset(peaks, chr == ch)
    g_sub <- subset(genes, chr == ch)
    
#For each gene, find overlapping peaks
for (i in seq_len(nrow(g_sub))) {
      g <- g_sub[i, ]
      hits <- which(p_sub$end > g$gene_start & p_sub$start < g$gene_end)
      
if (length(hits) > 0) {
        tmp <- p_sub[hits, ]
        tmp$gene <- g$gene
        tmp$overlap_bp <- pmin(tmp$end, g$gene_end) - pmax(tmp$start, g$gene_start)
        tmp <- tmp[tmp$overlap_bp > 0, ]
        overlap_list[[length(overlap_list) + 1]] <- tmp
      }
    }
  }
  
# Combine overlaps
overlaps <- do.call(rbind, overlap_list)

# Order 
overlaps <- overlaps[order(overlaps$chr, overlaps$start, overlaps$end), ]

  
#Summarize per gene
peaks_per_gene <- do.call(rbind,
                            lapply(split(overlaps, overlaps$gene), function(x)
                              data.frame(
                                gene = unique(x$gene),
                                n_peaks = nrow(x),
                                total_overlap_bp = sum(x$overlap_bp)
                              ))
  )
  
# Top 20 genes
top20 <- head(peaks_per_gene[order(-peaks_per_gene$total_overlap_bp), ], 20)
  
return(list(
    overlaps_df10 = overlaps,
    peaks_per_gene_df10 = peaks_per_gene,
    top20_df10 = top20
  ))
}


# SHOW RESULTS 
res_df10 <- task10_df("atac_peaks.bed.csv", "gene_annotation.bed.csv")
head(res_df10$overlaps_df10)
head(res_df10$peaks_per_gene_df10)
res_df10$top20_df10
```

# TASK 11

## DATA.TABLE VERSION

```{r}
# DATA.TABLE VERSION
#' @param variants_file Path to the variants CSV file (columns: chr, pos, sample_id, impact)
#' @param genes_file Path to the gene annotation CSV file (columns: chr, start, end, gene)
#' @export

task11_dt <- function(variants_file = "variants.csv",
                      genes_file    = "gene_annotation.bed.csv") {
  
#Load library 
library(data.table)
  
# Read data
  variants <- fread(variants_file, colClasses = "character")
  genes    <- fread(genes_file,    colClasses = "character")
  
# Convert numeric columns
variants[, pos := as.integer(pos)]
genes[, c("start","end") := .(as.integer(start), as.integer(end))]
  
#Create overlaps 
overlaps_list <- lapply(1:nrow(variants), function(i) {
    v <- variants[i]
    subset <- genes[chr == v$chr & start <= v$pos & end >= v$pos]
    if (nrow(subset) > 0) {
      data.table(chr = v$chr,
                 gene = subset$gene,
                 sample_id = v$sample_id,
                 impact = v$impact)
    } else NULL
  })
  
overlaps <- rbindlist(overlaps_list, use.names = TRUE, fill = TRUE)
  
# Count HIGH-impact variants
counts <- overlaps[impact == "HIGH", .(n_high = .N), by = .(gene, sample_id)]
setorder(counts, gene, sample_id)
  
# Genes with HIGH-impact variants in all samples
n_samples <- uniqueN(variants$sample_id)
genes_all <- counts[, .N, by = gene][N == n_samples, gene]


return(list(
    overlaps_dt11      = overlaps,
    counts_per_gene_dt = counts,
    genes_high_all_dt  = genes_all
  ))
} 
#SHOW RESULTS
res_dt11 <- task11_dt("variants.csv", "gene_annotation.bed.csv")
head(res_dt11$overlaps_dt11, 5)
head(res_dt11$counts_per_gene_dt, 5)
res_dt11$genes_high_all_dt

```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION
#' @param variants_file Path to the variants CSV file (columns: chr, pos, sample_id, impact)
#' @param genes_file Path to the gene annotation CSV file (columns: chr, start, end, gene)
#' @export

task11_df <- function(variants_file = "variants.csv",
                      genes_file    = "gene_annotation.bed.csv") {
  
#Read data
variants <- read.csv(variants_file, stringsAsFactors = FALSE)
genes    <- read.csv(genes_file, stringsAsFactors = FALSE)
  
variants$chr <- as.character(variants$chr)
variants$pos <- as.integer(variants$pos)
genes$chr    <- as.character(genes$chr)
genes$start  <- as.integer(genes$start)
genes$end    <- as.integer(genes$end)
genes$gene   <- as.character(genes$gene)
  
# Create overlaps
overlaps <- data.frame(chr=character(), gene=character(),
                         sample_id=character(), impact=character(),
                         stringsAsFactors = FALSE)
  
for (i in 1:nrow(variants)) {
    v <- variants[i, ]
    matches <- subset(genes, chr == v$chr &
                        start <= v$pos &
                        end >= v$pos)
if (nrow(matches) > 0) {
    new_rows <- data.frame(chr = v$chr,
                             gene = matches$gene,
                             sample_id = v$sample_id,
                             impact = v$impact,
                             stringsAsFactors = FALSE)
      overlaps <- rbind(overlaps, new_rows)
    }
  }
  
# Count HIGH-impact variants
high <- subset(overlaps, impact == "HIGH")
if (nrow(high) == 0) {
    counts <- data.frame(gene=character(), sample_id=character(), n_high=integer())
  } else {
    counts <- aggregate(
      list(n_high = rep(1, nrow(high))),
      by = list(gene = high$gene, sample_id = high$sample_id),
      FUN = sum
    )
    counts <- counts[order(counts$gene, counts$sample_id), ]
  }
  
# Genes with HIGH-impact variants in all samples
n_samples <- length(unique(variants$sample_id))
  if (nrow(counts) == 0) {
    genes_all <- character(0)
  } else {
    gene_counts <- aggregate(sample_id ~ gene, data = counts,
                             FUN = function(x) length(unique(x)))
    genes_all <- sort(gene_counts$gene[gene_counts$sample_id == n_samples])
  }
  

  return(list(
    overlaps_df11      = overlaps,
    counts_per_gene_df = counts,
    genes_high_all_df  = genes_all
  ))
}

#SHOW RESULTS
res_df11 <- task11_df("variants.csv", "gene_annotation.bed.csv")
head(res_df11$overlaps_df11, 5)
head(res_df11$counts_per_gene_df, 5)
res_df11$genes_high_all_df
```

# TASK 12

## DATA.TABLE VERSION

```{r}
#DATA.TABLE VERSION 

#' @param cohortA_file path to cohortA_samples.csv
#' @param cohortB_file path to cohortB_samples.csv
#' @param counts_file  path to bulk_counts_long.csv (gene, sample_id, count)

task12_dt <- function(cohortA_file = "cohortA_samples.csv",
                      cohortB_file = "cohortB_samples.csv",
                      counts_file  = "bulk_counts_long.csv") {
  
# Load library
  library(data.table)

# Read cohort files
A <- fread(cohortA_file)
B <- fread(cohortB_file)
  
#  Combine cohorts
combined <- rbindlist(list(A, B), use.names = TRUE, fill = TRUE)
  
# Order by cohort, condition, sample_id
order_cols <- intersect(c("cohort", "condition", "sample_id"), names(combined))
if (length(order_cols) > 0) setorderv(combined, order_cols)
  
# Read counts and join by sample_id
counts <- fread(counts_file)
merged <- merge(counts, combined, by = "sample_id", allow.cartesian = TRUE)
  
# Compute variance per gene (sorted descending)
var_dt <- merged[, .(variance = var(count, na.rm = TRUE)), by = gene]
var_dt <- var_dt[order(-variance, gene)]
top_genes <- var_dt$gene[1:100]
  
# Compute per-cohort/per-condition mean counts
summary_dt <- merged[gene %in% top_genes,
                       .(mean_count = mean(count, na.rm = TRUE)),
                       by = .(gene, cohort, condition)]
setorderv(summary_dt, c("cohort", "condition", "gene"))
  
# Column alignment summary (silent)
alignment_summary <- data.table(
  Status = c("In both", "Only in A", "Only in B"),
  Count  = c(length(intersect(names(A), names(B))),
               length(setdiff(names(A), names(B))),
               length(setdiff(names(B), names(A))))
  )
  
# Return all results
return(list(
    combined_samples = combined,
    merged_counts    = merged,
    top_genes_var    = var_dt,
    summary_counts   = summary_dt,
    column_check     = alignment_summary
  ))
}

# SHOW RESULTS
res_dt12 <- task12_dt("cohortA_samples.csv", "cohortB_samples.csv", "bulk_counts_long.csv")

head(res_dt12$combined_samples, 5)
head(res_dt12$top_genes_var, 5)
head(res_dt12$summary_counts, 5)
```

## DATA.FRAME VERSION

```{r}
# DATA.FRAME VERSION

#' @param cohortA_file path to cohortA_samples.csv
#' @param cohortB_file path to cohortB_samples.csv
#' @param counts_file  path to bulk_counts_long.csv (gene, sample_id, count)

task12_df <- function(cohortA_file = "cohortA_samples.csv",
                      cohortB_file = "cohortB_samples.csv",
                      counts_file  = "bulk_counts_long.csv") {
  
# Read and align cohorts
A <- read.csv(cohortA_file, stringsAsFactors = FALSE)
B <- read.csv(cohortB_file, stringsAsFactors = FALSE)
  
all_cols <- union(names(A), names(B))
for (col in setdiff(all_cols, names(A))) A[[col]] <- NA
for (col in setdiff(all_cols, names(B))) B[[col]] <- NA
  
combined_df <- rbind(A[all_cols], B[all_cols])
  
# Order by cohort, condition, sample_id
  order_cols <- intersect(c("cohort", "condition", "sample_id"), names(combined_df))
  if (length(order_cols) > 0)
    combined_df <- combined_df[do.call(order, combined_df[order_cols]), ]
  
# Read counts and join by sample_id
  counts <- read.csv(counts_file, stringsAsFactors = FALSE)
  merged <- merge(counts, combined_df, by = "sample_id")
  
# Compute variance per gene and select top 100
var_df <- aggregate(count ~ gene, data = merged, FUN = var, na.rm = TRUE)
names(var_df)[2] <- "variance"
var_df <- var_df[order(-var_df$variance, var_df$gene), ]
top_genes <- var_df$gene[1:100]
  
# Compute per-cohort/per-condition mean counts
filtered <- merged[merged$gene %in% top_genes, ]
summary_counts_df <- aggregate(count ~ gene + cohort + condition,
                                 data = filtered,
                                 FUN = function(x) mean(x, na.rm = TRUE))
names(summary_counts_df)[4] <- "mean_count"

summary_counts_df <- summary_counts_df[order(summary_counts_df$cohort,
                                               summary_counts_df$condition,
                                               summary_counts_df$gene), ]
  
# Column alignment summary
  alignment_summary <- data.frame(
    Status = c("In both", "Only in A", "Only in B"),
    Count  = c(length(intersect(names(A), names(B))),
               length(setdiff(names(A), names(B))),
               length(setdiff(names(B), names(A))))
  )
  
return(list(
    combined_samples  = combined_df,
    merged_counts     = merged,
    top_genes_var     = var_df,
    summary_counts_df = summary_counts_df,
    column_check      = alignment_summary
  ))
}

# SHOW RESULTS 
res_df12 <- task12_df("cohortA_samples.csv",
                      "cohortB_samples.csv", "bulk_counts_long.csv")
head(res_df12$combined_samples, 5)
head(res_df12$top_genes_var, 5)
head(res_df12$summary_counts_df, 5)
```

# FINAL REVISION

## DATA.TABLE VERSION

```{r echo=TRUE}
# DATA.TABLE VERSION 

#' @param integration_file path to annotated integration CSV
#'   (columns: cell, integration_cluster)
#' @param annotation_file path to annotation CSV
#'   (columns: cell, cell_type, sample_type)
#' @export

task13_dt <- function(integration_file = "annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv",
                      annotation_file  = "nt_combined_clustering.output.csv") {
  
# Load libraries
library(data.table)
library(ggplot2)

# Prepare output directory
if (!dir.exists("output")) dir.create("output")
  
# Read input files
integ_dt <- fread(integration_file)
annot_dt <- fread(annotation_file)
  
# Clean IDs
integ_dt[, cell := gsub("_X_", "", cell)]
  
# Merge
merged_dt13 <- merge(integ_dt, annot_dt, by = "cell", sort = FALSE)
  
# Count per cluster and cell type
count_dt13 <- merged_dt13[, .(count = .N), by = .(integration_cluster, cell_type)]
setorder(count_dt13, integration_cluster, cell_type)
  
# Summary table: add tissue type and normalized percentages
summary_dt13 <- merged_dt13[, .(count = .N),
                              by = .(integration_cluster, cell_type, sample_type)]
summary_dt13[, total := sum(count), by = .(integration_cluster, sample_type)]
summary_dt13[, percent := round((count / total) * 100, 2)]

setorder(summary_dt13, integration_cluster, sample_type, cell_type)

# Order 
summary_dt13[, integration_cluster := factor(integration_cluster,
                                             levels = sort(unique(integration_cluster)))]
summary_dt13[, sample_type := factor(sample_type, levels = c("N", "T"))]
  
# Plot 1: Distribution plot
plot_counts_dt13 <- ggplot(summary_dt13,
                             aes(x = factor(integration_cluster),
                                 y = count,
                                 fill = cell_type)) +
geom_bar(stat = "identity") +
facet_wrap(~sample_type) +
theme_minimal() +
labs(title = "Cell Type Distribution by Cluster and Tissue Type",
         x = "Integration Cluster",
         y = "Number of Cells",
         fill = "Cell Type") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
# Plot 2: Distribution plot with normalized percentages
plot_percent_dt13 <- ggplot(summary_dt13,
                              aes(x = factor(integration_cluster),
                                  y = percent,
                                  fill = cell_type)) +
    geom_bar(stat = "identity") +
    facet_wrap(~sample_type) +
    theme_minimal() +
    labs(title = "Cell Distribution by Cluster and Tissue Type (Normalized %)",
         x = "Integration Cluster",
         y = "Percentage (%)",
         fill = "Cell Type") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
# Save outputs
fwrite(merged_dt13, "output/merged_dt13.csv")
fwrite(count_dt13, "output/count_dt13.csv")
fwrite(summary_dt13, "output/summary_dt13.csv")
ggsave("output/plot_counts_dt13.pdf", plot_counts_dt13, width = 8, height = 5)
ggsave("output/plot_percent_dt13.pdf", plot_percent_dt13, width = 8, height = 5)
  

  return(list(
    merged_dt13       = merged_dt13,
    count_dt13        = count_dt13,
    summary_dt13      = summary_dt13,
    plot_counts_dt13  = plot_counts_dt13,
    plot_percent_dt13 = plot_percent_dt13
  ))
}

# SHOW RESULTS
res_dt13 <- task13_dt("annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv",
                      "nt_combined_clustering.output.csv")
head(res_dt13$merged_dt13, 5)
head(res_dt13$count_dt13, 5)
head(res_dt13$summary_dt13, 5)
print(res_dt13$plot_counts_dt13)     
print(res_dt13$plot_percent_dt13)    


```

## DATA.FRAME VERSION

```{r echo=TRUE}
# DATA.FRAME VERSION 

#' @param integration_file path to annotated integration CSV
#'   (columns: cell, integration_cluster)
#' @param annotation_file path to annotation CSV
#'   (columns: cell, cell_type, sample_type)
#' @export

task13_df <- function(integration_file = "annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv",
                      annotation_file  = "nt_combined_clustering.output.csv") {
  
# Prepare output directory
if (!dir.exists("output")) dir.create("output")
  
# Read input files
integ_df <- read.csv(integration_file, stringsAsFactors = FALSE)
annot_df <- read.csv(annotation_file, stringsAsFactors = FALSE)
  
# Clean IDs
integ_df$cell <- gsub("_X_", "", integ_df$cell)
  
# Merge
merged_df13 <- merge(integ_df, annot_df, by = "cell")
  
# Count per cluster
count_df13 <- as.data.frame(table(
    integration_cluster = merged_df13$integration_cluster,
    cell_type = merged_df13$cell_type
  ))
names(count_df13)[3] <- "count"
count_df13$count <- as.integer(count_df13$count)
count_df13 <- count_df13[count_df13$count > 0, ]
count_df13 <- count_df13[order(count_df13$integration_cluster, count_df13$cell_type), ]
  
# Summary with sample_type and normalized %
summary_df13 <- as.data.frame(table(
    integration_cluster = merged_df13$integration_cluster,
    cell_type = merged_df13$cell_type,
    sample_type = merged_df13$sample_type
  ))
  
names(summary_df13)[4] <- "count"
summary_df13$count <- as.integer(summary_df13$count)
summary_df13 <- summary_df13[summary_df13$count > 0, ]
summary_df13$total <- ave(summary_df13$count,
                            interaction(summary_df13$integration_cluster, summary_df13$sample_type),
                            FUN = sum)
summary_df13$percent <- round((summary_df13$count / summary_df13$total) * 100, 2)
summary_df13 <- summary_df13[order(summary_df13$integration_cluster,
                                     summary_df13$sample_type,
                                     summary_df13$cell_type), ]
# Order 
summary_df13$integration_cluster <- factor(summary_df13$integration_cluster,
                                           levels = sort(unique(summary_df13$integration_cluster)))
summary_df13$sample_type <- factor(summary_df13$sample_type,
                                   levels = c("N", "T"))

# Plot 1: Distribution plot
  plot_counts_df13 <- ggplot(summary_df13,
                             aes(x = factor(integration_cluster),
                                 y = count,
                                 fill = cell_type)) +
    geom_bar(stat = "identity") +
    facet_wrap(~sample_type) +
    theme_minimal() +
    labs(title = "Cell Type Distribution by Cluster and Tissue Type",
         x = "Integration Cluster",
         y = "Number of Cells",
         fill = "Cell Type") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
# Plot 2: Distribution plot with normalized percentages
  plot_percent_df13 <- ggplot(summary_df13,
                              aes(x = factor(integration_cluster),
                                  y = percent,
                                  fill = cell_type)) +
    geom_bar(stat = "identity") +
    facet_wrap(~sample_type) +
    theme_minimal() +
    labs(title = "Cell Distribution by Cluster and Tissue Type (Normalized %)",
         x = "Integration Cluster",
         y = "Percentage (%)",
         fill = "Cell Type") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
# Save outputs
write.csv(merged_df13, "output/merged_df13.csv", row.names = FALSE)
write.csv(count_df13, "output/count_df13.csv", row.names = FALSE)
write.csv(summary_df13, "output/summary_df13.csv", row.names = FALSE)
ggsave("output/plot_counts_df13.pdf", plot_counts_df13, width = 8, height = 5)
ggsave("output/plot_percent_df13.pdf", plot_percent_df13, width = 8, height = 5)
  

return(list(
    merged_df13       = merged_df13,
    count_df13        = count_df13,
    summary_df13      = summary_df13,
    plot_counts_df13  = plot_counts_df13,
    plot_percent_df13 = plot_percent_df13
  ))
}

# SHOW RESULTS 
res_df13 <- task13_df("annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv",
                      "nt_combined_clustering.output.csv")
head(res_df13$merged_df13, 5)
head(res_df13$count_df13, 5)
head(res_df13$summary_df13, 5)
print(res_df13$plot_counts_df13)     
print(res_df13$plot_percent_df13)    

```
